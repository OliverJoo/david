#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•Œê³ ë¦¬ì¦˜ ë³µì¡ë„ ê³„ì‚° ë° ë¶„ì„ í´ë˜ìŠ¤
Python 3.12 í˜¸í™˜
"""

import time
import tracemalloc
import functools
import inspect
from typing import Callable, Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass
from enum import Enum
import math


class ComplexityType(Enum):
    """ë³µì¡ë„ ìœ í˜• ì—´ê±°í˜•"""
    CONSTANT = "O(1)"
    LOGARITHMIC = "O(log n)"
    LINEAR = "O(n)"
    LINEARITHMIC = "O(n log n)"
    QUADRATIC = "O(nÂ²)"
    CUBIC = "O(nÂ³)"
    EXPONENTIAL = "O(2^n)"
    FACTORIAL = "O(n!)"


@dataclass
class PerformanceResult:
    """ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼"""
    input_size: int
    execution_time: float
    memory_usage: int
    function_name: str
    complexity_estimate: Optional[str] = None


class ComplexityCalculator:
    """ì•Œê³ ë¦¬ì¦˜ ë³µì¡ë„ ê³„ì‚° ë° ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        """ë³µì¡ë„ ê³„ì‚°ê¸° ì´ˆê¸°í™”"""
        self.results: List[PerformanceResult] = []
        self.complexity_patterns = {
            ComplexityType.CONSTANT: lambda n: 1,
            ComplexityType.LOGARITHMIC: lambda n: math.log2(n) if n > 0 else 0,
            ComplexityType.LINEAR: lambda n: n,
            ComplexityType.LINEARITHMIC: lambda n: n * math.log2(n) if n > 0 else 0,
            ComplexityType.QUADRATIC: lambda n: n ** 2,
            ComplexityType.CUBIC: lambda n: n ** 3,
            ComplexityType.EXPONENTIAL: lambda n: 2 ** min(n, 20),  # ì œí•œëœ ì§€ìˆ˜
            ComplexityType.FACTORIAL: lambda n: math.factorial(min(n, 10))  # ì œí•œëœ íŒ©í† ë¦¬ì–¼
        }

    def measure_performance(
            self,
            func: Callable,
            input_sizes: List[int],
            data_generator: Optional[Callable[[int], Any]] = None
    ) -> List[PerformanceResult]:
        """
        í•¨ìˆ˜ì˜ ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ ì…ë ¥ í¬ê¸°ì— ëŒ€í•´ ì¸¡ì •

        Args:
            func: ì¸¡ì •í•  í•¨ìˆ˜
            input_sizes: í…ŒìŠ¤íŠ¸í•  ì…ë ¥ í¬ê¸°ë“¤
            data_generator: ì…ë ¥ ë°ì´í„° ìƒì„± í•¨ìˆ˜

        Returns:
            ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not callable(func):
            raise ValueError("funcëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        if not input_sizes:
            raise ValueError("input_sizesëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        results = []

        # ê¸°ë³¸ ë°ì´í„° ìƒì„±ê¸° (ë¦¬ìŠ¤íŠ¸)
        if data_generator is None:
            data_generator = lambda n: list(range(n))

        for size in input_sizes:
            if size < 0:
                print(f"ê²½ê³ : ìŒìˆ˜ ì…ë ¥ í¬ê¸° {size} ê±´ë„ˆë›°ê¸°")
                continue

            try:
                # ì…ë ¥ ë°ì´í„° ìƒì„±
                test_data = data_generator(size)

                # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
                tracemalloc.start()

                # ì‹œê°„ ì¸¡ì •
                start_time = time.perf_counter()

                # í•¨ìˆ˜ ì‹¤í–‰
                if inspect.signature(func).parameters:
                    result = func(test_data)
                else:
                    result = func()

                end_time = time.perf_counter()

                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
                current, peak = tracemalloc.get_traced_memory()
                tracemalloc.stop()

                # ê²°ê³¼ ì €ì¥
                perf_result = PerformanceResult(
                    input_size=size,
                    execution_time=end_time - start_time,
                    memory_usage=peak,
                    function_name=func.__name__
                )

                results.append(perf_result)

            except Exception as e:
                print(f"í¬ê¸° {size}ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        self.results.extend(results)
        return results

    def estimate_complexity(self, results: List[PerformanceResult]) -> str:
        """
        ì¸¡ì • ê²°ê³¼ë¡œë¶€í„° ì‹œê°„ ë³µì¡ë„ ì¶”ì •

        Args:
            results: ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼

        Returns:
            ì¶”ì •ëœ ë³µì¡ë„ ë¬¸ìì—´
        """
        if len(results) < 2:
            return "ë°ì´í„° ë¶€ì¡±: ë³µì¡ë„ ì¶”ì • ë¶ˆê°€"

        # ì…ë ¥ í¬ê¸°ì™€ ì‹¤í–‰ ì‹œê°„ ì¶”ì¶œ
        sizes = [r.input_size for r in results if r.input_size > 0]
        times = [r.execution_time for r in results if r.input_size > 0]

        if len(sizes) < 2:
            return "ìœ íš¨í•œ ë°ì´í„° ë¶€ì¡±"

        best_fit = None
        best_error = float('inf')

        # ê° ë³µì¡ë„ íŒ¨í„´ê³¼ ë¹„êµ
        for complexity_type, pattern_func in self.complexity_patterns.items():
            try:
                # íŒ¨í„´ ê°’ ê³„ì‚°
                pattern_values = [pattern_func(n) for n in sizes]

                # ì •ê·œí™”ë¥¼ ìœ„í•´ ìµœëŒ€ê°’ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                if max(pattern_values) > 0 and max(times) > 0:
                    normalized_pattern = [v / max(pattern_values) for v in pattern_values]
                    normalized_times = [t / max(times) for t in times]

                    # í‰ê·  ì œê³± ì˜¤ì°¨ ê³„ì‚°
                    error = sum((p - t) ** 2 for p, t in zip(normalized_pattern, normalized_times)) / len(times)

                    if error < best_error:
                        best_error = error
                        best_fit = complexity_type.value

            except (OverflowError, ValueError, ZeroDivisionError):
                continue

        return best_fit if best_fit else "ë³µì¡ë„ ì¶”ì • ì‹¤íŒ¨"

    def analyze_space_complexity(self, results: List[PerformanceResult]) -> str:
        """
        ê³µê°„ ë³µì¡ë„ ë¶„ì„

        Args:
            results: ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼

        Returns:
            ê³µê°„ ë³µì¡ë„ ì¶”ì • ê²°ê³¼
        """
        if len(results) < 2:
            return "ë°ì´í„° ë¶€ì¡±: ê³µê°„ ë³µì¡ë„ ë¶„ì„ ë¶ˆê°€"

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ìœ¨ ê³„ì‚°
        memory_ratios = []
        for i in range(1, len(results)):
            if results[i - 1].memory_usage > 0:
                size_ratio = results[i].input_size / results[i - 1].input_size
                memory_ratio = results[i].memory_usage / results[i - 1].memory_usage
                if size_ratio > 0:
                    memory_ratios.append(memory_ratio / size_ratio)

        if not memory_ratios:
            return "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ ë¶ˆê°€"

        avg_ratio = sum(memory_ratios) / len(memory_ratios)

        # ë¹„ìœ¨ì— ë”°ë¥¸ ë³µì¡ë„ ì¶”ì •
        if avg_ratio < 1.2:
            return "O(1) - ìƒìˆ˜ ê³µê°„"
        elif avg_ratio < 2.0:
            return "O(log n) - ë¡œê·¸ ê³µê°„"
        elif avg_ratio < 3.0:
            return "O(n) - ì„ í˜• ê³µê°„"
        else:
            return "O(nÂ²) ì´ìƒ - ê³ ì°¨ ê³µê°„"

    def benchmark_function(
            self,
            func: Callable,
            iterations: int = 100,
            input_size: int = 1000
    ) -> Dict[str, float]:
        """
        í•¨ìˆ˜ì˜ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰

        Args:
            func: ë²¤ì¹˜ë§ˆí¬í•  í•¨ìˆ˜
            iterations: ë°˜ë³µ íšŸìˆ˜
            input_size: ì…ë ¥ í¬ê¸°

        Returns:
            ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        if iterations <= 0:
            raise ValueError("iterationsëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        times = []
        test_data = list(range(input_size))

        for _ in range(iterations):
            try:
                start_time = time.perf_counter()
                if inspect.signature(func).parameters:
                    func(test_data)
                else:
                    func()
                end_time = time.perf_counter()
                times.append(end_time - start_time)
            except Exception as e:
                print(f"ë²¤ì¹˜ë§ˆí¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        if not times:
            return {"error": "ëª¨ë“  ì¸¡ì • ì‹¤íŒ¨"}

        return {
            "min_time": min(times),
            "max_time": max(times),
            "avg_time": sum(times) / len(times),
            "total_time": sum(times),
            "iterations": len(times)
        }

    def compare_algorithms(
            self,
            algorithms: Dict[str, Callable],
            input_sizes: List[int] = None
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë¹„êµ

        Args:
            algorithms: ë¹„êµí•  ì•Œê³ ë¦¬ì¦˜ë“¤ {ì´ë¦„: í•¨ìˆ˜}
            input_sizes: í…ŒìŠ¤íŠ¸í•  ì…ë ¥ í¬ê¸°ë“¤

        Returns:
            ë¹„êµ ê²°ê³¼
        """
        if not algorithms:
            raise ValueError("ë¹„êµí•  ì•Œê³ ë¦¬ì¦˜ì´ ì—†ìŠµë‹ˆë‹¤.")

        if input_sizes is None:
            input_sizes = [100, 500, 1000, 2000, 5000]

        comparison_results = {}

        for name, func in algorithms.items():
            try:
                print(f"\n{name} ë¶„ì„ ì¤‘...")
                results = self.measure_performance(func, input_sizes)
                complexity = self.estimate_complexity(results)

                comparison_results[name] = {
                    "results": results,
                    "estimated_complexity": complexity,
                    "avg_time": sum(r.execution_time for r in results) / len(results) if results else 0,
                    "total_memory": sum(r.memory_usage for r in results) if results else 0
                }

            except Exception as e:
                print(f"{name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                comparison_results[name] = {"error": str(e)}

        return comparison_results

    def generate_report(self) -> str:
        """ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not self.results:
            return "ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        report = ["=== ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ ===\n"]

        # í•¨ìˆ˜ë³„ ê·¸ë£¹í™”
        functions = {}
        for result in self.results:
            if result.function_name not in functions:
                functions[result.function_name] = []
            functions[result.function_name].append(result)

        for func_name, func_results in functions.items():
            report.append(f"ğŸ“Š í•¨ìˆ˜: {func_name}")
            report.append(f"ì¸¡ì • íšŸìˆ˜: {len(func_results)}")

            if func_results:
                times = [r.execution_time for r in func_results]
                memories = [r.memory_usage for r in func_results]

                report.append(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {sum(times) / len(times):.6f}ì´ˆ")
                report.append(f"ìµœëŒ€ ì‹¤í–‰ ì‹œê°„: {max(times):.6f}ì´ˆ")
                report.append(f"í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©: {sum(memories) / len(memories):,} bytes")

                complexity = self.estimate_complexity(func_results)
                report.append(f"ì¶”ì • ì‹œê°„ ë³µì¡ë„: {complexity}")

                space_complexity = self.analyze_space_complexity(func_results)
                report.append(f"ì¶”ì • ê³µê°„ ë³µì¡ë„: {space_complexity}")

            report.append("")

        return "\n".join(report)

    def clear_results(self) -> None:
        """ì €ì¥ëœ ê²°ê³¼ ì´ˆê¸°í™”"""
        self.results.clear()


# ë°ì½”ë ˆì´í„° í•¨ìˆ˜ë“¤
def measure_time(calculator: ComplexityCalculator):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.perf_counter()
            result = func(*args, **kwargs)
            end_time = time.perf_counter()

            # ì…ë ¥ í¬ê¸° ì¶”ì •
            input_size = 0
            if args:
                first_arg = args[0]
                if hasattr(first_arg, '__len__'):
                    input_size = len(first_arg)
                elif isinstance(first_arg, int):
                    input_size = first_arg

            perf_result = PerformanceResult(
                input_size=input_size,
                execution_time=end_time - start_time,
                memory_usage=0,  # ë©”ëª¨ë¦¬ëŠ” ë³„ë„ ì¸¡ì • í•„ìš”
                function_name=func.__name__
            )

            calculator.results.append(perf_result)
            return result

        return wrapper

    return decorator


# ì˜ˆì œ ì‚¬ìš©ë²• ë° í…ŒìŠ¤íŠ¸
def demo_algorithms():
    """ë°ëª¨ìš© ì•Œê³ ë¦¬ì¦˜ë“¤"""

    def bubble_sort(arr):
        """ë²„ë¸” ì •ë ¬ - O(nÂ²)"""
        arr = arr.copy()
        n = len(arr)
        for i in range(n):
            for j in range(0, n - i - 1):
                if arr[j] > arr[j + 1]:
                    arr[j], arr[j + 1] = arr[j + 1], arr[j]
        return arr

    def linear_search(arr):
        """ì„ í˜• íƒìƒ‰ - O(n)"""
        target = len(arr) // 2
        for i, item in enumerate(arr):
            if item == target:
                return i
        return -1

    def binary_search_wrapper(arr):
        """ì´ì§„ íƒìƒ‰ ë˜í¼ - O(log n)"""
        arr = sorted(arr)
        target = len(arr) // 2

        def binary_search(arr, target, left, right):
            if left > right:
                return -1

            mid = (left + right) // 2
            if arr[mid] == target:
                return mid
            elif arr[mid] > target:
                return binary_search(arr, target, left, mid - 1)
            else:
                return binary_search(arr, target, mid + 1, right)

        return binary_search(arr, target, 0, len(arr) - 1)

    return {
        "bubble_sort": bubble_sort,
        "linear_search": linear_search,
        "binary_search": binary_search_wrapper
    }


if __name__ == "__main__":
    # ë³µì¡ë„ ê³„ì‚°ê¸° ì‚¬ìš© ì˜ˆì œ
    print("=== ComplexityCalculator ì‚¬ìš© ì˜ˆì œ ===\n")

    calculator = ComplexityCalculator()

    # 1. ë‹¨ì¼ í•¨ìˆ˜ ì„±ëŠ¥ ì¸¡ì •
    algorithms = demo_algorithms()

    print("1. ë²„ë¸” ì •ë ¬ ì„±ëŠ¥ ì¸¡ì •")
    bubble_results = calculator.measure_performance(
        algorithms["bubble_sort"],
        [100, 200, 500, 1000],
        lambda n: list(range(n, 0, -1))  # ì—­ìˆœ ë°ì´í„°
    )

    for result in bubble_results:
        print(f"í¬ê¸° {result.input_size}: {result.execution_time:.6f}ì´ˆ")

    complexity = calculator.estimate_complexity(bubble_results)
    print(f"ì¶”ì • ë³µì¡ë„: {complexity}\n")

    # 2. ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
    print("2. ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë¹„êµ")
    comparison = calculator.compare_algorithms(
        algorithms,
        [100, 300, 500, 800, 1000]
    )

    for name, data in comparison.items():
        if "error" not in data:
            print(f"{name}: {data['estimated_complexity']}")
        else:
            print(f"{name}: ì˜¤ë¥˜ - {data['error']}")

    print("\n3. ì¢…í•© ë³´ê³ ì„œ")
    print(calculator.generate_report())
