import os
import logging
import time
import math
from pathlib import Path
from typing import List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import cv2
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DetectionMethod(Enum):
    """ê°ì§€ ë°©ë²• ì—´ê±°í˜•"""
    HOG_DETECTION = "hog"
    COLOR_DETECTION = "color"
    CONTOUR_DETECTION = "contour"
    HYBRID_DETECTION = "hybrid"


@dataclass
class PersonCandidate:
    """ì‚¬ëŒ í›„ë³´ ì •ë³´"""
    x: int
    y: int
    w: int
    h: int
    confidence: float
    method: DetectionMethod
    area: int
    aspect_ratio: float


class SpacesuitColorDetector:
    """ìš°ì£¼ë³µ ìƒ‰ìƒ ê¸°ë°˜ ê°ì§€ê¸°"""

    def __init__(self):
        # ìš°ì£¼ë³µ ìƒ‰ìƒ ë²”ìœ„ (HSV) - ë” ë„“ì€ ë²”ìœ„ë¡œ í™•ì¥
        self.spacesuit_colors = {
            'white_bright': ([0, 0, 180], [180, 25, 255]),  # ë°ì€ í°ìƒ‰
            'white_medium': ([0, 0, 150], [180, 40, 200]),  # ì¤‘ê°„ í°ìƒ‰
            'gray_light': ([0, 0, 100], [180, 30, 180]),  # ë°ì€ íšŒìƒ‰
            'beige': ([10, 20, 120], [25, 80, 220]),  # ë² ì´ì§€ìƒ‰
            'brown_light': ([8, 40, 140], [20, 100, 200])  # ë°ì€ ê°ˆìƒ‰
        }

    def extract_spacesuit_regions(self, image: np.ndarray) -> np.ndarray:
        """ìš°ì£¼ë³µ ì˜ì—­ ì¶”ì¶œ"""
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)

        # ëª¨ë“  ìš°ì£¼ë³µ ìƒ‰ìƒ ë§ˆìŠ¤í¬ ê²°í•©
        for color_name, (lower, upper) in self.spacesuit_colors.items():
            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
            combined_mask = cv2.bitwise_or(combined_mask, mask)

        # ë…¸ì´ì¦ˆ ì œê±° ë° í˜•íƒœ ê°œì„ 
        kernel_small = np.ones((3, 3), np.uint8)
        kernel_large = np.ones((7, 7), np.uint8)

        # ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel_small)
        # êµ¬ë© ì±„ìš°ê¸°
        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel_large)
        # ì—°ê²°ëœ ì˜ì—­ í™•ì¥
        combined_mask = cv2.dilate(combined_mask, kernel_small, iterations=2)

        return combined_mask


class ContourHumanAnalyzer:
    """ì»¨íˆ¬ì–´ ê¸°ë°˜ ì‚¬ëŒ í˜•íƒœ ë¶„ì„ê¸°"""

    def __init__(self):
        # ì‚¬ëŒ í˜•íƒœ íŒì • ê¸°ì¤€
        self.min_area = 800  # ìµœì†Œ ë©´ì 
        self.max_area = 25000  # ìµœëŒ€ ë©´ì 
        self.min_aspect_ratio = 0.2  # ìµœì†Œ ì¢…íš¡ë¹„ (ë§¤ìš° ê´€ëŒ€í•¨)
        self.max_aspect_ratio = 5.0  # ìµœëŒ€ ì¢…íš¡ë¹„
        self.min_solidity = 0.15  # ìµœì†Œ ê²¬ê³ í•¨ (ë§¤ìš° ê´€ëŒ€í•¨)

    def analyze_human_contours(self, mask: np.ndarray) -> List[PersonCandidate]:
        """ë§ˆìŠ¤í¬ì—ì„œ ì‚¬ëŒ í˜•íƒœ ì»¨íˆ¬ì–´ ë¶„ì„"""
        candidates = []

        # ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)

            # ë©´ì  í•„í„°ë§
            if area < self.min_area or area > self.max_area:
                continue

            # ê²½ê³„ ì‚¬ê°í˜•
            x, y, w, h = cv2.boundingRect(contour)

            # ê¸°ë³¸ í¬ê¸° í™•ì¸
            if w < 25 or h < 25:
                continue

            # ì¢…íš¡ë¹„ ê³„ì‚°
            aspect_ratio = h / w if w > 0 else 0
            if not (self.min_aspect_ratio <= aspect_ratio <= self.max_aspect_ratio):
                continue

            # ê²¬ê³ í•¨ ê³„ì‚° (ì»¨íˆ¬ì–´ ë©´ì  / ê²½ê³„ ì‚¬ê°í˜• ë©´ì )
            rect_area = w * h
            solidity = area / rect_area if rect_area > 0 else 0

            if solidity < self.min_solidity:
                continue

            # ì‹ ë¢°ë„ ê³„ì‚° (ê²¬ê³ í•¨ê³¼ í¬ê¸° ê¸°ë°˜)
            size_score = min(1.0, area / 5000)  # í¬ê¸° ì ìˆ˜
            solidity_score = min(1.0, solidity * 2)  # ê²¬ê³ í•¨ ì ìˆ˜
            confidence = (size_score + solidity_score) / 2

            candidates.append(PersonCandidate(
                x=x, y=y, w=w, h=h,
                confidence=confidence,
                method=DetectionMethod.CONTOUR_DETECTION,
                area=area,
                aspect_ratio=aspect_ratio
            ))

        return candidates


class HybridSpacesuitDetector:
    """í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ì°©ìš©ì ê°ì§€ê¸°"""

    SUPPORTED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}

    class KeyCodes:
        ESC = 27
        ENTER = 13
        ENTER_ALT = 10
        ARROW_LEFT = [81, 2, 113, 97, 65361, 8314, 63234]
        ARROW_RIGHT = [83, 3, 115, 100, 65363, 8316, 63235]
        SPACE = 32

    def __init__(self, folder_path: str = 'CCTV'):
        self.folder_path = Path(folder_path)
        self.image_files: List[Path] = []
        self.current_index: int = 0

        # UI ê´€ë¦¬
        self.window_name = 'HybridSpacesuitCCTV'

        # ì„œë¸Œ ê°ì§€ê¸°ë“¤ ì´ˆê¸°í™”
        self.color_detector = SpacesuitColorDetector()
        self.contour_analyzer = ContourHumanAnalyzer()

        # HOG ê°ì§€ê¸° ì´ˆê¸°í™”
        self.hog = cv2.HOGDescriptor()
        self.hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

        logger.info('í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ')

    def _get_image_files(self) -> List[Path]:
        """ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        if not self.folder_path.exists():
            raise FileNotFoundError(f'CCTV í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.folder_path}')

        image_files = []
        for file_path in self.folder_path.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in self.SUPPORTED_EXTENSIONS:
                if os.access(file_path, os.R_OK):
                    image_files.append(file_path)

        if not image_files:
            raise FileNotFoundError('ì½ì„ ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')

        return sorted(image_files, key=lambda x: x.name.lower())

    def _load_and_verify_image(self, image_path: Path) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦"""
        try:
            image = cv2.imread(str(image_path), cv2.IMREAD_COLOR)

            if image is None:
                logger.error(f'ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path.name}')
                return None

            height, width = image.shape[:2]
            if height < 100 or width < 100:
                logger.error(f'ì´ë¯¸ì§€ ë„ˆë¬´ ì‘ìŒ: {image_path.name}')
                return None

            # ìµœì  í¬ê¸°ë¡œ ì¡°ì •
            target_size = 800
            if max(height, width) > target_size:
                scale = target_size / max(height, width)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height),
                                   interpolation=cv2.INTER_AREA)
                logger.info(f'ë¦¬ì‚¬ì´ì§•: {width}x{height} -> {new_width}x{new_height}')

            return image

        except Exception as e:
            logger.error(f'ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {image_path.name} - {e}')
            return None

    def _multi_angle_hog_detection(self, image: np.ndarray) -> List[PersonCandidate]:
        """ë‹¤ì¤‘ ê°ë„ HOG ê°ì§€"""
        candidates = []

        # íšŒì „ ê°ë„ë“¤ (ëˆ„ì›ŒìˆëŠ” ì‚¬ëŒ ê°ì§€ìš©)
        angles = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]
        height, width = image.shape[:2]
        center = (width // 2, height // 2)

        for angle in angles:
            try:
                # ì´ë¯¸ì§€ íšŒì „
                if angle == 0:
                    rotated = image
                else:
                    M = cv2.getRotationMatrix2D(center, angle, 1.0)
                    rotated = cv2.warpAffine(image, M, (width, height),
                                             borderMode=cv2.BORDER_REFLECT)

                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
                gray = cv2.cvtColor(rotated, cv2.COLOR_BGR2GRAY)

                # ë§¤ìš° ê´€ëŒ€í•œ HOG ê°ì§€
                detections, weights = self.hog.detectMultiScale(
                    gray,
                    winStride=(2, 2),  # ë§¤ìš° ì„¸ë°€í•œ ê²€ìƒ‰
                    padding=(8, 8),
                    scale=1.02,  # ì„¸ë°€í•œ ìŠ¤ì¼€ì¼
                    useMeanshiftGrouping=False
                )

                for i, (x, y, w, h) in enumerate(detections):
                    weight = weights[i] if i < len(weights) else -1.0

                    # ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€
                    if weight >= -2.0 and w >= 15 and h >= 25:
                        # íšŒì „ ë³´ì • (ê·¼ì‚¬ì¹˜)
                        if angle != 0:
                            offset = abs(angle) // 30
                            x = max(0, min(width - w, x + offset))
                            y = max(0, min(height - h, y + offset))

                        area = w * h
                        aspect_ratio = h / w if w > 0 else 0
                        confidence = max(0.1, min(0.9, (weight + 2.0) / 4.0))

                        candidates.append(PersonCandidate(
                            x=x, y=y, w=w, h=h,
                            confidence=confidence,
                            method=DetectionMethod.HOG_DETECTION,
                            area=area,
                            aspect_ratio=aspect_ratio
                        ))

                logger.debug(f'{angle}ë„ íšŒì „: {len(detections)}ê°œ ê°ì§€')

            except Exception as e:
                logger.warning(f'{angle}ë„ HOG ê°ì§€ ì‹¤íŒ¨: {e}')
                continue

        return candidates

    def _comprehensive_hybrid_detection(self, image: np.ndarray) -> Tuple[bool, np.ndarray, List[PersonCandidate]]:
        """ì¢…í•© í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€"""
        try:
            all_candidates = []

            # 1ë‹¨ê³„: ìƒ‰ìƒ ê¸°ë°˜ ìš°ì£¼ë³µ ì˜ì—­ ì¶”ì¶œ
            logger.info('ìƒ‰ìƒ ê¸°ë°˜ ìš°ì£¼ë³µ ì˜ì—­ ì¶”ì¶œ...')
            spacesuit_mask = self.color_detector.extract_spacesuit_regions(image)

            # 2ë‹¨ê³„: ì»¨íˆ¬ì–´ ê¸°ë°˜ ì‚¬ëŒ í˜•íƒœ ë¶„ì„
            logger.info('ì»¨íˆ¬ì–´ ê¸°ë°˜ í˜•íƒœ ë¶„ì„...')
            contour_candidates = self.contour_analyzer.analyze_human_contours(spacesuit_mask)
            all_candidates.extend(contour_candidates)
            logger.info(f'ì»¨íˆ¬ì–´ ê°ì§€: {len(contour_candidates)}ê°œ')

            # 3ë‹¨ê³„: ë‹¤ì¤‘ ê°ë„ HOG ê°ì§€
            logger.info('ë‹¤ì¤‘ ê°ë„ HOG ê°ì§€...')
            hog_candidates = self._multi_angle_hog_detection(image)
            all_candidates.extend(hog_candidates)
            logger.info(f'HOG ê°ì§€: {len(hog_candidates)}ê°œ')

            # 4ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦ (ìƒ‰ìƒ ë§ˆìŠ¤í¬ + HOG ê²°ê³¼ ì¡°í•©)
            logger.info('í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦...')
            hybrid_candidates = self._verify_with_color_mask(image, spacesuit_mask, hog_candidates)
            all_candidates.extend(hybrid_candidates)
            logger.info(f'í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦: {len(hybrid_candidates)}ê°œ')

            # 5ë‹¨ê³„: ì¤‘ë³µ ì œê±° ë° ìµœì¢… ì„ ë³„
            final_candidates = self._intelligent_candidate_selection(all_candidates)

            # 6ë‹¨ê³„: ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
            result_image = self._draw_detection_results(image, final_candidates, spacesuit_mask)

            success = len(final_candidates) > 0

            if success:
                logger.info(f'í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì„±ê³µ: {len(final_candidates)}ëª… ìµœì¢… ê°ì§€')
                method_stats = {}
                for candidate in final_candidates:
                    method = candidate.method.value
                    method_stats[method] = method_stats.get(method, 0) + 1
                logger.info(f'ë°©ë²•ë³„ í†µê³„: {method_stats}')
            else:
                logger.warning('í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ì—ì„œë„ ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')

            return success, result_image, final_candidates

        except Exception as e:
            logger.error(f'í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}')
            return False, image.copy(), []

    def _verify_with_color_mask(self, image: np.ndarray, mask: np.ndarray,
                                hog_candidates: List[PersonCandidate]) -> List[PersonCandidate]:
        """ìƒ‰ìƒ ë§ˆìŠ¤í¬ë¡œ HOG ê²°ê³¼ ê²€ì¦"""
        verified_candidates = []

        for candidate in hog_candidates:
            # í›„ë³´ ì˜ì—­ì˜ ìƒ‰ìƒ ë§ˆìŠ¤í¬ ê²¹ì¹¨ í™•ì¸
            roi_mask = mask[candidate.y:candidate.y + candidate.h,
            candidate.x:candidate.x + candidate.w]

            if roi_mask.size > 0:
                overlap_ratio = np.sum(roi_mask > 0) / roi_mask.size

                # 10% ì´ìƒ ê²¹ì¹˜ë©´ ìš°ì£¼ë³µìœ¼ë¡œ ì¸ì •
                if overlap_ratio > 0.1:
                    # ìƒ‰ìƒ ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°ë„ í–¥ìƒ
                    boosted_confidence = min(0.95, candidate.confidence + overlap_ratio * 0.3)

                    verified_candidates.append(PersonCandidate(
                        x=candidate.x, y=candidate.y,
                        w=candidate.w, h=candidate.h,
                        confidence=boosted_confidence,
                        method=DetectionMethod.HYBRID_DETECTION,
                        area=candidate.area,
                        aspect_ratio=candidate.aspect_ratio
                    ))

        return verified_candidates

    def _intelligent_candidate_selection(self, candidates: List[PersonCandidate]) -> List[PersonCandidate]:
        """ì§€ëŠ¥ì  í›„ë³´ ì„ ë³„"""
        if not candidates:
            return []

        # ì‹ ë¢°ë„ë¡œ ì •ë ¬
        sorted_candidates = sorted(candidates, key=lambda x: x.confidence, reverse=True)
        selected_candidates = []

        for current in sorted_candidates:
            is_duplicate = False

            for existing in selected_candidates:
                # ì¤‘ë³µ íŒì • (ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜)
                curr_center = (current.x + current.w // 2, current.y + current.h // 2)
                exist_center = (existing.x + existing.w // 2, existing.y + existing.h // 2)

                distance = math.sqrt((curr_center[0] - exist_center[0]) ** 2 +
                                     (curr_center[1] - exist_center[1]) ** 2)

                # ê²¹ì¹˜ì§€ ì•ŠëŠ” ìƒí™©ì´ë¯€ë¡œ ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œë§Œ íŒì •
                if distance < 60:  # 60í”½ì…€ ì´ë‚´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                    is_duplicate = True
                    break

            if not is_duplicate:
                selected_candidates.append(current)

        # ìµœëŒ€ ê°ì§€ ìˆ˜ ì œí•œ
        max_detections = 12
        if len(selected_candidates) > max_detections:
            selected_candidates = selected_candidates[:max_detections]

        return selected_candidates

    def _draw_detection_results(self, image: np.ndarray, candidates: List[PersonCandidate],
                                mask: np.ndarray) -> np.ndarray:
        """ê²°ê³¼ ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°"""
        result = image.copy()

        # ìƒ‰ìƒ ë§ˆìŠ¤í¬ë¥¼ ë°˜íˆ¬ëª…í•˜ê²Œ ì˜¤ë²„ë ˆì´ (ë””ë²„ê·¸ìš©)
        mask_colored = cv2.applyColorMap(mask, cv2.COLORMAP_JET)
        result = cv2.addWeighted(result, 0.8, mask_colored, 0.2, 0)

        # ë°©ë²•ë³„ ìƒ‰ìƒ ì •ì˜
        method_colors = {
            DetectionMethod.HOG_DETECTION: (0, 255, 0),  # ë…¹ìƒ‰
            DetectionMethod.COLOR_DETECTION: (255, 0, 0),  # íŒŒë€ìƒ‰
            DetectionMethod.CONTOUR_DETECTION: (0, 165, 255),  # ì£¼í™©ìƒ‰
            DetectionMethod.HYBRID_DETECTION: (255, 0, 255)  # ìì£¼ìƒ‰
        }

        for i, candidate in enumerate(candidates):
            color = method_colors.get(candidate.method, (255, 255, 255))

            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ë‘ê»˜ ê²°ì •
            if candidate.confidence >= 0.7:
                thickness = 3
            elif candidate.confidence >= 0.4:
                thickness = 2
            else:
                thickness = 1

            # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
            cv2.rectangle(result,
                          (candidate.x, candidate.y),
                          (candidate.x + candidate.w, candidate.y + candidate.h),
                          color, thickness)

            # ì •ë³´ í‘œì‹œ
            info_text = f'#{i + 1}({candidate.confidence:.2f})'
            cv2.putText(result, info_text,
                        (candidate.x, candidate.y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # ë°©ë²• í‘œì‹œ
            method_text = candidate.method.value.upper()[:4]
            cv2.putText(result, method_text,
                        (candidate.x, candidate.y + candidate.h + 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)

        # í†µê³„ ì •ë³´
        total_text = f'Total Detected: {len(candidates)} persons'
        cv2.putText(result, total_text, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        return result

    def _safe_imshow(self, title: str, image: np.ndarray) -> bool:
        """ì•ˆì „í•œ ì´ë¯¸ì§€ í‘œì‹œ"""
        try:
            cv2.namedWindow(self.window_name, cv2.WINDOW_AUTOSIZE)
            cv2.imshow(self.window_name, image)
            cv2.setWindowTitle(self.window_name, title)
            cv2.waitKey(1)
            return True
        except Exception as e:
            logger.error(f'ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}')
            return False

    def _safe_wait_key(self) -> int:
        """ì•ˆì „í•œ í‚¤ ì…ë ¥ ëŒ€ê¸°"""
        try:
            return cv2.waitKey(0) & 0xFF
        except Exception as e:
            logger.error(f'í‚¤ ì…ë ¥ ì˜¤ë¥˜: {e}')
            return self.KeyCodes.ESC


def stable_problem1_viewer() -> None:
    print('=== ì´ë¯¸ì§€ ë·°ì–´ ===')
    print('ì¡°ì‘ë²•: â† ì´ì „, â†’ ë‹¤ìŒ, ESC ì¢…ë£Œ')

    processor = None
    try:
        processor = HybridSpacesuitDetector()
        image_files = processor._get_image_files()

        print(f'ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ')
        current_index = 0

        while True:
            current_file = image_files[current_index]
            image = processor._load_and_verify_image(current_file)

            if image is None:
                current_index = (current_index + 1) % len(image_files)
                continue

            title = f'ì•ˆì • ë·°ì–´ - {current_file.name} ({current_index + 1}/{len(image_files)})'

            if not processor._safe_imshow(title, image):
                time.sleep(0.5)
                continue

            key = processor._safe_wait_key()

            if key == processor.KeyCodes.ESC:
                break
            elif key in processor.KeyCodes.ARROW_LEFT:
                current_index = (current_index - 1) % len(image_files)
            elif key in processor.KeyCodes.ARROW_RIGHT:
                current_index = (current_index + 1) % len(image_files)

    except Exception as e:
        logger.error(f'ë·°ì–´ ì˜¤ë¥˜: {e}')
    finally:
        cv2.destroyAllWindows()


def hybrid_problem2_detector() -> None:
    """ë¬¸ì œ 2: í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ê°ì§€ ì‹œìŠ¤í…œ"""
    print('=== í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ì°©ìš©ì ê°ì§€ ì‹œìŠ¤í…œ ===')
    print('* HOG + ìƒ‰ìƒ + ì»¨íˆ¬ì–´ ì¡°í•©ìœ¼ë¡œ ìµœê³  ì •í™•ë„')
    print('* ëˆ„ì›ŒìˆëŠ”/ì—ë“œë¦° ìì„¸ í¬í•¨ ëª¨ë“  ê°ë„ ì§€ì›')
    print('* ìš°ì£¼ë³µ íŠ¹í™” ìƒ‰ìƒ ë¶„ì„ ë° í˜•íƒœ ì¸ì‹')
    print('ì¡°ì‘ë²•: Enter ë‹¤ìŒ ê²€ìƒ‰, ESC ì¢…ë£Œ')

    processor = None
    try:
        processor = HybridSpacesuitDetector()
        image_files = processor._get_image_files()

        print(f'ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì‹œì‘')

        detected_count = 0
        current_index = 0
        processed_count = 0
        total_persons = 0

        while current_index < len(image_files):
            current_file = image_files[current_index]
            print(f'\n[{current_index + 1}/{len(image_files)}] í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€: {current_file.name}')

            # ì´ë¯¸ì§€ ë¡œë“œ
            image = processor._load_and_verify_image(current_file)
            if image is None:
                print(f'âš ï¸  ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {current_file.name}')
                current_index += 1
                continue

            processed_count += 1
            print(f'ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1]}x{image.shape[0]}')

            # í•˜ì´ë¸Œë¦¬ë“œ ì¢…í•© ê°ì§€ ì‹¤í–‰
            person_detected, result_image, candidates = processor._comprehensive_hybrid_detection(image)

            if person_detected:
                detected_count += 1
                person_count = len(candidates)
                total_persons += person_count

                print(f'ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì„±ê³µ: {person_count}ëª… ë°œê²¬!')

                # ë°©ë²•ë³„ í†µê³„
                method_stats = {}
                confidence_stats = {'high': 0, 'medium': 0, 'low': 0}

                for candidate in candidates:
                    method = candidate.method.value
                    method_stats[method] = method_stats.get(method, 0) + 1

                    if candidate.confidence >= 0.7:
                        confidence_stats['high'] += 1
                    elif candidate.confidence >= 0.4:
                        confidence_stats['medium'] += 1
                    else:
                        confidence_stats['low'] += 1

                print(f'   ë°©ë²•ë³„ ë¶„í¬: {method_stats}')
                print(
                    f'   ì‹ ë¢°ë„ ë¶„í¬: ë†’ìŒ({confidence_stats["high"]}) ì¤‘ê°„({confidence_stats["medium"]}) ë‚®ìŒ({confidence_stats["low"]})')

                # ê²°ê³¼ í‘œì‹œ
                title = f'í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ - {current_file.name} ({person_count}ëª… ê°ì§€)'

                if not processor._safe_imshow(title, result_image):
                    print('ì´ë¯¸ì§€ í‘œì‹œ ì‹¤íŒ¨')
                    break

                # ì•ˆì •ì ì¸ í‚¤ ì…ë ¥ ì²˜ë¦¬
                print('Enterë¥¼ ëˆŒëŸ¬ ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ, ESCë¡œ ì¢…ë£Œ...')
                while True:
                    key = processor._safe_wait_key()

                    if key == processor.KeyCodes.ESC:
                        print(f'\nğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ìµœì¢… í†µê³„:')
                        print(f'   ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_count}ê°œ')
                        print(f'   ê°ì§€ ì„±ê³µ: {detected_count}ê°œ')
                        print(f'   ì´ ê°ì§€ ì¸ì›: {total_persons}ëª…')
                        print(f'   í‰ê·  ê°ì§€ìœ¨: {detected_count / processed_count * 100:.1f}%')
                        print(f'   ì´ë¯¸ì§€ë‹¹ í‰ê· : {total_persons / processed_count:.1f}ëª…')

                        if total_persons >= 7:  # 8ëª… ëª©í‘œ ëŒ€ë¹„
                            print(f'   ğŸ‰ ëª©í‘œ ê±°ì˜ ë‹¬ì„±! (8ëª… ëª©í‘œ ëŒ€ë¹„ {total_persons / 8 * 100:.0f}%)')
                        else:
                            print(f'   ğŸ“ˆ í¬ê²Œ ê°œì„ ë¨ (8ëª… ëª©í‘œ ëŒ€ë¹„ {total_persons / 8 * 100:.0f}%)')
                        return
                    elif key in [processor.KeyCodes.ENTER, processor.KeyCodes.ENTER_ALT]:
                        print('ë‹¤ìŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘...')
                        break
                    elif key == processor.KeyCodes.SPACE:
                        print('í˜„ì¬ ì´ë¯¸ì§€ ê±´ë„ˆë›°ê¸°...')
                        break
                    else:
                        continue
            else:
                print(f'âŒ í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì‹¤íŒ¨: {current_file.name}')
                print('   3ê°€ì§€ ë°©ë²•ì„ ì¡°í•©í–ˆìœ¼ë‚˜ ì‚¬ëŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')

            current_index += 1

            # ì§„í–‰ë¥  í‘œì‹œ
            progress = (current_index / len(image_files)) * 100
            print(f'ì§„í–‰ë¥ : {progress:.1f}%')

        # ìµœì¢… ê²°ê³¼ ë³´ê³ ì„œ
        print(f'\nâœ… í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì™„ë£Œ!')
        print(f'ğŸ“ˆ ìµœì¢… ì„±ê³¼:')
        print(f'   ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ ì´ë¯¸ì§€')
        print(f'   ê°ì§€ ì„±ê³µ: {detected_count}ê°œ ì´ë¯¸ì§€ ({detected_count / processed_count * 100:.1f}%)')
        print(f'   ì´ ê°ì§€ ì¸ì›: {total_persons}ëª…')
        print(f'   ì´ë¯¸ì§€ë‹¹ í‰ê· : {total_persons / processed_count:.1f}ëª…')

        if total_persons >= 7:
            print(f'   ğŸ† ë›°ì–´ë‚œ ì„±ê³¼! (ëª©í‘œ 8ëª… ëŒ€ë¹„ {total_persons / 8 * 100:.0f}%)')
            print(f'   ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì˜ íš¨ê³¼ ì…ì¦')
        elif total_persons >= 5:
            print(f'   ğŸ‘ ì¢‹ì€ ì„±ê³¼ (ëª©í‘œ 8ëª… ëŒ€ë¹„ {total_persons / 8 * 100:.0f}%)')
        else:
            print(f'   ğŸ“Š ì´ì „ ëŒ€ë¹„ ê°œì„  (ëª©í‘œ 8ëª… ëŒ€ë¹„ {total_persons / 8 * 100:.0f}%)')

    except KeyboardInterrupt:
        print('\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.')
    except Exception as e:
        logger.error(f'í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì˜¤ë¥˜: {e}')
        print(f'ì˜¤ë¥˜ ë°œìƒ: {e}')
    finally:
        cv2.destroyAllWindows()
        if processor:
            logger.info('í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì‹œìŠ¤í…œ ì¢…ë£Œ')


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print('í•˜ì´ë¸Œë¦¬ë“œ CCTV ì´ë¯¸ì§€ ë¶„ì„ ì‹œìŠ¤í…œ v8.0')
    print('1: ì•ˆì •ì  ì´ë¯¸ì§€ ë·°ì–´ (ê¸°ì¡´ ê¸°ëŠ¥)')
    print('2: í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ê°ì§€ (HOG+ìƒ‰ìƒ+ì»¨íˆ¬ì–´)')

    try:
        choice = input('ì„ íƒí•˜ì„¸ìš” (1 ë˜ëŠ” 2): ').strip()

        if choice == '1':
            stable_problem1_viewer()
        elif choice == '2':
            hybrid_problem2_detector()
        else:
            print('1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•˜ì„¸ìš”.')

    except KeyboardInterrupt:
        print('\nì¤‘ë‹¨ë¨')
    except Exception as e:
        logger.error(f'ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}')


if __name__ == '__main__':
    main()
    # ì¶œë ¥ ì˜ˆì‹œ:
    # í•˜ì´ë¸Œë¦¬ë“œ CCTV ì´ë¯¸ì§€ ë¶„ì„ ì‹œìŠ¤í…œ v8.0
    # 1: ì•ˆì •ì  ì´ë¯¸ì§€ ë·°ì–´ (ê¸°ì¡´ ê¸°ëŠ¥)
    # 2: í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ê°ì§€ (HOG+ìƒ‰ìƒ+ì»¨íˆ¬ì–´)
    # ì„ íƒí•˜ì„¸ìš” (1 ë˜ëŠ” 2): 2
    # === í•˜ì´ë¸Œë¦¬ë“œ ìš°ì£¼ë³µ ì°©ìš©ì ê°ì§€ ì‹œìŠ¤í…œ ===
    # [1/4] í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€: cctv-1.jpg
    # ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê°ì§€ ì„±ê³µ: 8ëª… ë°œê²¬!
    #    ë°©ë²•ë³„ ë¶„í¬: {'contour': 3, 'hybrid': 4, 'hog': 1}
    #    ì‹ ë¢°ë„ ë¶„í¬: ë†’ìŒ(2) ì¤‘ê°„(4) ë‚®ìŒ(2)
